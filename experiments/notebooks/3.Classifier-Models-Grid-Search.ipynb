{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"../evaluate_results/full/outer/LogisticRegression-split_x_y_split_with_one_hot_encoding-{'multi_class': ['auto'], 'solver': ['liblinear']}-cross_entropy-(1 of 5).csv\",\n",
       " \"../evaluate_results/full/outer/LogisticRegression-split_x_y_with_bag_of_words-{'multi_class': ['auto'], 'solver': ['liblinear']}-cross_entropy-(2 of 5).csv\",\n",
       " \"../evaluate_results/full/outer/MLPClassifier-split_x_y_split_with_one_hot_encoding-{'hidden_layer_sizes': [20, 40, 80, 100], 'max_iter': [800]}-accuracy-(3 of 5).csv\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def highlight_max(data):\n",
    "    percent = data.str.contains('%').any()\n",
    "\n",
    "    data = data.str.split(expand=True)\n",
    "    percent = data[0].str.contains('%').any()\n",
    "\n",
    "    data[0] = data[0].replace('\\\\\\%','', regex=True).replace('\\$','', regex=True).astype(float)\n",
    "    data[0] = np.where(data[0] == data[0].max(), '\\mathbf{'+ str(data[0].max()) + '}', data[0])\n",
    "    if percent:\n",
    "        return '$' + data[0] + '\\% ' + data[1] + ' ' + data[2]\n",
    "    else:\n",
    "        return '$' + data[0] + ' ' + data[1] + ' ' + data[2]\n",
    "\n",
    "    return data\n",
    "\n",
    "dataset_path = 'full'\n",
    "#dataset_path = 'amauri'\n",
    "#dataset_path = 'full_with_tfidf'\n",
    "#dataset_path = 'small'\n",
    "\n",
    "files = glob.glob(f'../evaluate_results/{dataset_path}/outer/*.csv', recursive=True)\n",
    "\n",
    "print(len(files), 'files')\n",
    "files[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_params</th>\n",
       "      <th>column</th>\n",
       "      <th>i_outer</th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>refit</th>\n",
       "      <th>split_method</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'multi_class': 'auto', 'solver': 'liblinear'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'multi_class': ['auto'], 'solver': ['liblinea...</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>split_x_y_split_with_one_hot_encoding</td>\n",
       "      <td>0.475751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'multi_class': 'auto', 'solver': 'liblinear'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'multi_class': ['auto'], 'solver': ['liblinea...</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>split_x_y_split_with_one_hot_encoding</td>\n",
       "      <td>0.676674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      best_params  column  i_outer    metric  \\\n",
       "0  {'multi_class': 'auto', 'solver': 'liblinear'}       0        0  accuracy   \n",
       "1  {'multi_class': 'auto', 'solver': 'liblinear'}       0        0     hit@5   \n",
       "\n",
       "                model                                             params  \\\n",
       "0  LogisticRegression  {'multi_class': ['auto'], 'solver': ['liblinea...   \n",
       "1  LogisticRegression  {'multi_class': ['auto'], 'solver': ['liblinea...   \n",
       "\n",
       "           refit                           split_method     value  \n",
       "0  cross_entropy  split_x_y_split_with_one_hot_encoding  0.475751  \n",
       "1  cross_entropy  split_x_y_split_with_one_hot_encoding  0.676674  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all data\n",
    "data = pd.concat([pd.read_csv(file, index_col=[0]) for file in files])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>split_method</th>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">KNeighborsClassifier</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">split_x_y_split_with_one_hot_encoding</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.356083</td>\n",
       "      <td>0.131148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hit@5</th>\n",
       "      <td>0.525216</td>\n",
       "      <td>0.128174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map@5</th>\n",
       "      <td>0.303942</td>\n",
       "      <td>0.155788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         mean  \\\n",
       "model                split_method                          metric               \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding accuracy  0.356083   \n",
       "                                                           hit@5     0.525216   \n",
       "                                                           map@5     0.303942   \n",
       "\n",
       "                                                                          std  \n",
       "model                split_method                          metric              \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding accuracy  0.131148  \n",
       "                                                           hit@5     0.128174  \n",
       "                                                           map@5     0.155788  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = data.groupby(['model', 'split_method', 'metric'])['value'].agg([\"mean\", \"std\"])\n",
    "result.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result as pivot table\n",
    "\n",
    "(Beauty table bellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"5\" halign=\"left\">std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>map@5</th>\n",
       "      <th>mdcg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>map@5</th>\n",
       "      <th>mdcg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>split_method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">KNeighborsClassifier</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.356083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525216</td>\n",
       "      <td>0.303942</td>\n",
       "      <td>0.544766</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.128174</td>\n",
       "      <td>0.155788</td>\n",
       "      <td>0.103685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.342662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520976</td>\n",
       "      <td>0.300250</td>\n",
       "      <td>0.539627</td>\n",
       "      <td>0.135818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131489</td>\n",
       "      <td>0.156469</td>\n",
       "      <td>0.107570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LogisticRegression</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.389859</td>\n",
       "      <td>2.778379</td>\n",
       "      <td>0.593544</td>\n",
       "      <td>0.325379</td>\n",
       "      <td>0.591116</td>\n",
       "      <td>0.128102</td>\n",
       "      <td>0.643164</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.153554</td>\n",
       "      <td>0.096964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.342660</td>\n",
       "      <td>3.131092</td>\n",
       "      <td>0.515190</td>\n",
       "      <td>0.317795</td>\n",
       "      <td>0.544051</td>\n",
       "      <td>0.137130</td>\n",
       "      <td>0.695718</td>\n",
       "      <td>0.140499</td>\n",
       "      <td>0.160684</td>\n",
       "      <td>0.109393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLPClassifier</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.347435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552361</td>\n",
       "      <td>0.307099</td>\n",
       "      <td>0.556736</td>\n",
       "      <td>0.127203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>0.151721</td>\n",
       "      <td>0.096470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.352223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.560688</td>\n",
       "      <td>0.319760</td>\n",
       "      <td>0.563953</td>\n",
       "      <td>0.130594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117527</td>\n",
       "      <td>0.149939</td>\n",
       "      <td>0.099597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.394791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585606</td>\n",
       "      <td>0.334276</td>\n",
       "      <td>0.584850</td>\n",
       "      <td>0.122213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.120280</td>\n",
       "      <td>0.156483</td>\n",
       "      <td>0.099676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.380994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582834</td>\n",
       "      <td>0.333675</td>\n",
       "      <td>0.582085</td>\n",
       "      <td>0.130818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.120735</td>\n",
       "      <td>0.155682</td>\n",
       "      <td>0.101609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                mean  \\\n",
       "metric                                                      accuracy   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.356083   \n",
       "                     split_x_y_with_bag_of_words            0.342662   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.389859   \n",
       "                     split_x_y_with_bag_of_words            0.342660   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.347435   \n",
       "                     split_x_y_with_bag_of_words            0.352223   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.394791   \n",
       "                     split_x_y_with_bag_of_words            0.380994   \n",
       "\n",
       "                                                                          \\\n",
       "metric                                                     cross_entropy   \n",
       "model                split_method                                          \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding      2.778379   \n",
       "                     split_x_y_with_bag_of_words                3.131092   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                         hit@5   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.525216   \n",
       "                     split_x_y_with_bag_of_words            0.520976   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.593544   \n",
       "                     split_x_y_with_bag_of_words            0.515190   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.552361   \n",
       "                     split_x_y_with_bag_of_words            0.560688   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.585606   \n",
       "                     split_x_y_with_bag_of_words            0.582834   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                         map@5   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.303942   \n",
       "                     split_x_y_with_bag_of_words            0.300250   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.325379   \n",
       "                     split_x_y_with_bag_of_words            0.317795   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.307099   \n",
       "                     split_x_y_with_bag_of_words            0.319760   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.334276   \n",
       "                     split_x_y_with_bag_of_words            0.333675   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                          mdcg   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.544766   \n",
       "                     split_x_y_with_bag_of_words            0.539627   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.591116   \n",
       "                     split_x_y_with_bag_of_words            0.544051   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.556736   \n",
       "                     split_x_y_with_bag_of_words            0.563953   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.584850   \n",
       "                     split_x_y_with_bag_of_words            0.582085   \n",
       "\n",
       "                                                                 std  \\\n",
       "metric                                                      accuracy   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.131148   \n",
       "                     split_x_y_with_bag_of_words            0.135818   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.128102   \n",
       "                     split_x_y_with_bag_of_words            0.137130   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.127203   \n",
       "                     split_x_y_with_bag_of_words            0.130594   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.122213   \n",
       "                     split_x_y_with_bag_of_words            0.130818   \n",
       "\n",
       "                                                                          \\\n",
       "metric                                                     cross_entropy   \n",
       "model                split_method                                          \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding      0.643164   \n",
       "                     split_x_y_with_bag_of_words                0.695718   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                         hit@5   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.128174   \n",
       "                     split_x_y_with_bag_of_words            0.131489   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.113773   \n",
       "                     split_x_y_with_bag_of_words            0.140499   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.111177   \n",
       "                     split_x_y_with_bag_of_words            0.117527   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.120280   \n",
       "                     split_x_y_with_bag_of_words            0.120735   \n",
       "\n",
       "                                                                                \n",
       "metric                                                         map@5      mdcg  \n",
       "model                split_method                                               \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.155788  0.103685  \n",
       "                     split_x_y_with_bag_of_words            0.156469  0.107570  \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.153554  0.096964  \n",
       "                     split_x_y_with_bag_of_words            0.160684  0.109393  \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.151721  0.096470  \n",
       "                     split_x_y_with_bag_of_words            0.149939  0.099597  \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.156483  0.099676  \n",
       "                     split_x_y_with_bag_of_words            0.155682  0.101609  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table = result.pivot_table(index=['model', 'split_method'], columns='metric', values=['mean', 'std'])\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Cute' Pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"4\" halign=\"left\">std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>map@5</th>\n",
       "      <th>mdcg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>map@5</th>\n",
       "      <th>mdcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(RBM, split_x_y_split_with_one_hot_encoding)</th>\n",
       "      <td>0.308956</td>\n",
       "      <td>0.504236</td>\n",
       "      <td>0.310148</td>\n",
       "      <td>0.526222</td>\n",
       "      <td>0.138047</td>\n",
       "      <td>0.134807</td>\n",
       "      <td>0.153247</td>\n",
       "      <td>0.10864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  mean                      \\\n",
       "metric                                        accuracy     hit@5     map@5   \n",
       "(RBM, split_x_y_split_with_one_hot_encoding)  0.308956  0.504236  0.310148   \n",
       "\n",
       "                                                             std            \\\n",
       "metric                                            mdcg  accuracy     hit@5   \n",
       "(RBM, split_x_y_split_with_one_hot_encoding)  0.526222  0.138047  0.134807   \n",
       "\n",
       "                                                                 \n",
       "metric                                           map@5     mdcg  \n",
       "(RBM, split_x_y_split_with_one_hot_encoding)  0.153247  0.10864  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../rbm_results-early-10000.csv', index_col=0)\n",
    "\n",
    "data['metric'].replace('Accuracy', 'accuracy', inplace=True)\n",
    "data['metric'].replace('Hit@5', 'hit@5', inplace=True)\n",
    "data['metric'].replace('MAP@5', 'map@5', inplace=True)\n",
    "data['metric'].replace('MDCG', 'mdcg', inplace=True)\n",
    "\n",
    "\n",
    "data['total_missing'] = data['missing'].str.split(',').str.len() + 1\n",
    "data['total_missing'] = np.where(data['missing'] == 'set()', 1, data['total_missing'])\n",
    "rbm_pivot = data.groupby(['metric', 'total_missing'])['value'].agg([\"mean\", \"std\"]) \\\n",
    "    .pivot_table(index=['total_missing'], columns='metric', values=['mean', 'std'])\n",
    "rbm_pivot.iloc[0]\n",
    "rbm_hide_1 = rbm_pivot.iloc[0].to_frame().T\n",
    "rbm_hide_1.index = [('RBM', 'split_x_y_split_with_one_hot_encoding')]\n",
    "rbm_hide_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy (std)</th>\n",
       "      <th>Hit@5 (std)</th>\n",
       "      <th>MDCG (std)</th>\n",
       "      <th>MAP@5 (std)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">$k$-NN</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$35.61\\% \\pm 13.11\\%$</td>\n",
       "      <td>$52.52\\% \\pm 12.82\\%$</td>\n",
       "      <td>$0.5448 \\pm 0.1037$</td>\n",
       "      <td>$30.39\\% \\pm 15.58\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$34.27\\% \\pm 13.58\\%$</td>\n",
       "      <td>$52.1\\% \\pm 13.15\\%$</td>\n",
       "      <td>$0.5396 \\pm 0.1076$</td>\n",
       "      <td>$30.03\\% \\pm 15.65\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$38.99\\% \\pm 12.81\\%$</td>\n",
       "      <td>$\\mathbf{59.35}\\% \\pm 11.38\\%$</td>\n",
       "      <td>$\\mathbf{0.5911} \\pm 0.0970$</td>\n",
       "      <td>$32.54\\% \\pm 15.36\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$34.27\\% \\pm 13.71\\%$</td>\n",
       "      <td>$51.52\\% \\pm 14.05\\%$</td>\n",
       "      <td>$0.5441 \\pm 0.1094$</td>\n",
       "      <td>$31.78\\% \\pm 16.07\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$34.74\\% \\pm 12.72\\%$</td>\n",
       "      <td>$55.24\\% \\pm 11.12\\%$</td>\n",
       "      <td>$0.5567 \\pm 0.0965$</td>\n",
       "      <td>$30.71\\% \\pm 15.17\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$35.22\\% \\pm 13.06\\%$</td>\n",
       "      <td>$56.07\\% \\pm 11.75\\%$</td>\n",
       "      <td>$0.564 \\pm 0.0996$</td>\n",
       "      <td>$31.98\\% \\pm 14.99\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$\\mathbf{39.48}\\% \\pm 12.22\\%$</td>\n",
       "      <td>$58.56\\% \\pm 12.03\\%$</td>\n",
       "      <td>$0.5849 \\pm 0.0997$</td>\n",
       "      <td>$\\mathbf{33.43}\\% \\pm 15.65\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$38.1\\% \\pm 13.08\\%$</td>\n",
       "      <td>$58.28\\% \\pm 12.07\\%$</td>\n",
       "      <td>$0.5821 \\pm 0.1016$</td>\n",
       "      <td>$33.37\\% \\pm 15.57\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBM</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$30.9\\% \\pm 13.80\\%$</td>\n",
       "      <td>$50.42\\% \\pm 13.48\\%$</td>\n",
       "      <td>$0.5262 \\pm 0.1086$</td>\n",
       "      <td>$31.01\\% \\pm 15.32\\%$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Accuracy (std)  \\\n",
       "Model               Embedding                                              \n",
       "$k$-NN              One-hot concatenated           $35.61\\% \\pm 13.11\\%$   \n",
       "                    Bag-of-words                   $34.27\\% \\pm 13.58\\%$   \n",
       "Logistic Regression One-hot concatenated           $38.99\\% \\pm 12.81\\%$   \n",
       "                    Bag-of-words                   $34.27\\% \\pm 13.71\\%$   \n",
       "MLP                 One-hot concatenated           $34.74\\% \\pm 12.72\\%$   \n",
       "                    Bag-of-words                   $35.22\\% \\pm 13.06\\%$   \n",
       "SVC                 One-hot concatenated  $\\mathbf{39.48}\\% \\pm 12.22\\%$   \n",
       "                    Bag-of-words                    $38.1\\% \\pm 13.08\\%$   \n",
       "RBM                 One-hot concatenated            $30.9\\% \\pm 13.80\\%$   \n",
       "\n",
       "                                                             Hit@5 (std)  \\\n",
       "Model               Embedding                                              \n",
       "$k$-NN              One-hot concatenated           $52.52\\% \\pm 12.82\\%$   \n",
       "                    Bag-of-words                    $52.1\\% \\pm 13.15\\%$   \n",
       "Logistic Regression One-hot concatenated  $\\mathbf{59.35}\\% \\pm 11.38\\%$   \n",
       "                    Bag-of-words                   $51.52\\% \\pm 14.05\\%$   \n",
       "MLP                 One-hot concatenated           $55.24\\% \\pm 11.12\\%$   \n",
       "                    Bag-of-words                   $56.07\\% \\pm 11.75\\%$   \n",
       "SVC                 One-hot concatenated           $58.56\\% \\pm 12.03\\%$   \n",
       "                    Bag-of-words                   $58.28\\% \\pm 12.07\\%$   \n",
       "RBM                 One-hot concatenated           $50.42\\% \\pm 13.48\\%$   \n",
       "\n",
       "                                                            MDCG (std)  \\\n",
       "Model               Embedding                                            \n",
       "$k$-NN              One-hot concatenated           $0.5448 \\pm 0.1037$   \n",
       "                    Bag-of-words                   $0.5396 \\pm 0.1076$   \n",
       "Logistic Regression One-hot concatenated  $\\mathbf{0.5911} \\pm 0.0970$   \n",
       "                    Bag-of-words                   $0.5441 \\pm 0.1094$   \n",
       "MLP                 One-hot concatenated           $0.5567 \\pm 0.0965$   \n",
       "                    Bag-of-words                    $0.564 \\pm 0.0996$   \n",
       "SVC                 One-hot concatenated           $0.5849 \\pm 0.0997$   \n",
       "                    Bag-of-words                   $0.5821 \\pm 0.1016$   \n",
       "RBM                 One-hot concatenated           $0.5262 \\pm 0.1086$   \n",
       "\n",
       "                                                             MAP@5 (std)  \n",
       "Model               Embedding                                             \n",
       "$k$-NN              One-hot concatenated           $30.39\\% \\pm 15.58\\%$  \n",
       "                    Bag-of-words                   $30.03\\% \\pm 15.65\\%$  \n",
       "Logistic Regression One-hot concatenated           $32.54\\% \\pm 15.36\\%$  \n",
       "                    Bag-of-words                   $31.78\\% \\pm 16.07\\%$  \n",
       "MLP                 One-hot concatenated           $30.71\\% \\pm 15.17\\%$  \n",
       "                    Bag-of-words                   $31.98\\% \\pm 14.99\\%$  \n",
       "SVC                 One-hot concatenated  $\\mathbf{33.43}\\% \\pm 15.65\\%$  \n",
       "                    Bag-of-words                   $33.37\\% \\pm 15.57\\%$  \n",
       "RBM                 One-hot concatenated           $31.01\\% \\pm 15.32\\%$  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_percentage(x):\n",
    "    return '{:2.2%}'.format(x).replace('%', '\\%')\n",
    "\n",
    "def format_std(x):\n",
    "    return '{:.4f}'.format(x)\n",
    "\n",
    "pivot_table2 = pd.concat([pivot_table, rbm_hide_1])\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy (std)': '$' + pivot_table2['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table2['std']['accuracy'].map(format_percentage) + \"$\",\n",
    "    'Hit@5 (std)':    '$' + pivot_table2['mean']['hit@5'].map(format_percentage)    + ' \\pm ' + pivot_table2['std']['hit@5'].map(format_percentage) + \"$\",\n",
    "    'MDCG (std)':     '$' + pivot_table2['mean']['mdcg'].map(format_std)            + ' \\pm ' + pivot_table2['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5 (std)':    '$' + pivot_table2['mean']['map@5'].map(format_percentage)    + ' \\pm ' + pivot_table2['std']['map@5'].map(format_percentage) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "new_pivot_table.apply(highlight_max).to_latex(\"table.tex\", escape=False)\n",
    "new_pivot_table.apply(highlight_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load dataset (hide two columns)\n",
    "\n",
    "### Two hidden columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duas colunas são ocultadas. A indicada em 'Column' é o índice da coluna colocada como 'y'. A outra coluna ocultada segue a seguinte regra\n",
      "Obs: A 5º coluna é mostrada como '3' pq o índice começa como zero e pq eu tiro a 2º coluna para computar os dados\n",
      "  - if column = 1, then the other hidden column is 5: P(column_1 | columns \\ {column_1, column_5})\n",
      "  - if column = 5, then the other hidden column is 1: P(column_5 | columns \\ {column_1, column_5})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MDCG</th>\n",
       "      <th>MAP@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">$k$-NN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No embedding</th>\n",
       "      <th>1</th>\n",
       "      <td>$20.18\\% \\pm 1.35\\%$</td>\n",
       "      <td>$39.75\\% \\pm 2.07\\%$</td>\n",
       "      <td>$0.4291 \\pm 0.0177$</td>\n",
       "      <td>$14.59\\% \\pm 0.54\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$44.05\\% \\pm 2.42\\%$</td>\n",
       "      <td>$58.91\\% \\pm 2.03\\%$</td>\n",
       "      <td>$0.6037 \\pm 0.0177$</td>\n",
       "      <td>$42.51\\% \\pm 1.45\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$24.06\\% \\pm 2.25\\%$</td>\n",
       "      <td>$47.39\\% \\pm 1.18\\%$</td>\n",
       "      <td>$0.4815 \\pm 0.0166$</td>\n",
       "      <td>$16.05\\% \\pm 0.51\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$46.65\\% \\pm 1.67\\%$</td>\n",
       "      <td>$\\mathbf{66.87}\\% \\pm 0.92\\%$</td>\n",
       "      <td>$\\mathbf{0.6516} \\pm 0.0104$</td>\n",
       "      <td>$44.3\\% \\pm 1.33\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$20.92\\% \\pm 1.79\\%$</td>\n",
       "      <td>$43.5\\% \\pm 1.85\\%$</td>\n",
       "      <td>$0.4508 \\pm 0.0153$</td>\n",
       "      <td>$15.47\\% \\pm 0.13\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$42.71\\% \\pm 0.89\\%$</td>\n",
       "      <td>$62.29\\% \\pm 1.81\\%$</td>\n",
       "      <td>$0.6182 \\pm 0.0034$</td>\n",
       "      <td>$42.27\\% \\pm 1.33\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$25.13\\% \\pm 1.95\\%$</td>\n",
       "      <td>$46.83\\% \\pm 1.89\\%$</td>\n",
       "      <td>$0.4769 \\pm 0.0135$</td>\n",
       "      <td>$16.4\\% \\pm 0.75\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$\\mathbf{47.2}\\% \\pm 1.46\\%$</td>\n",
       "      <td>$66.45\\% \\pm 1.12\\%$</td>\n",
       "      <td>$0.6509 \\pm 0.0095$</td>\n",
       "      <td>$\\mathbf{44.48}\\% \\pm 1.22\\%$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     Accuracy  \\\n",
       "Model               Embedding            Column                                 \n",
       "$k$-NN              No embedding         1               $20.18\\% \\pm 1.35\\%$   \n",
       "                                         3               $44.05\\% \\pm 2.42\\%$   \n",
       "Logistic Regression One-hot concatenated 1               $24.06\\% \\pm 2.25\\%$   \n",
       "                                         3               $46.65\\% \\pm 1.67\\%$   \n",
       "MLP                 One-hot concatenated 1               $20.92\\% \\pm 1.79\\%$   \n",
       "                                         3               $42.71\\% \\pm 0.89\\%$   \n",
       "SVC                 One-hot concatenated 1               $25.13\\% \\pm 1.95\\%$   \n",
       "                                         3       $\\mathbf{47.2}\\% \\pm 1.46\\%$   \n",
       "\n",
       "                                                                         Hit@5  \\\n",
       "Model               Embedding            Column                                  \n",
       "$k$-NN              No embedding         1                $39.75\\% \\pm 2.07\\%$   \n",
       "                                         3                $58.91\\% \\pm 2.03\\%$   \n",
       "Logistic Regression One-hot concatenated 1                $47.39\\% \\pm 1.18\\%$   \n",
       "                                         3       $\\mathbf{66.87}\\% \\pm 0.92\\%$   \n",
       "MLP                 One-hot concatenated 1                 $43.5\\% \\pm 1.85\\%$   \n",
       "                                         3                $62.29\\% \\pm 1.81\\%$   \n",
       "SVC                 One-hot concatenated 1                $46.83\\% \\pm 1.89\\%$   \n",
       "                                         3                $66.45\\% \\pm 1.12\\%$   \n",
       "\n",
       "                                                                         MDCG  \\\n",
       "Model               Embedding            Column                                 \n",
       "$k$-NN              No embedding         1                $0.4291 \\pm 0.0177$   \n",
       "                                         3                $0.6037 \\pm 0.0177$   \n",
       "Logistic Regression One-hot concatenated 1                $0.4815 \\pm 0.0166$   \n",
       "                                         3       $\\mathbf{0.6516} \\pm 0.0104$   \n",
       "MLP                 One-hot concatenated 1                $0.4508 \\pm 0.0153$   \n",
       "                                         3                $0.6182 \\pm 0.0034$   \n",
       "SVC                 One-hot concatenated 1                $0.4769 \\pm 0.0135$   \n",
       "                                         3                $0.6509 \\pm 0.0095$   \n",
       "\n",
       "                                                                         MAP@5  \n",
       "Model               Embedding            Column                                 \n",
       "$k$-NN              No embedding         1                $14.59\\% \\pm 0.54\\%$  \n",
       "                                         3                $42.51\\% \\pm 1.45\\%$  \n",
       "Logistic Regression One-hot concatenated 1                $16.05\\% \\pm 0.51\\%$  \n",
       "                                         3                 $44.3\\% \\pm 1.33\\%$  \n",
       "MLP                 One-hot concatenated 1                $15.47\\% \\pm 0.13\\%$  \n",
       "                                         3                $42.27\\% \\pm 1.33\\%$  \n",
       "SVC                 One-hot concatenated 1                 $16.4\\% \\pm 0.75\\%$  \n",
       "                                         3       $\\mathbf{44.48}\\% \\pm 1.22\\%$  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(f'../evaluate_results/hide_two/outer/*.csv', recursive=True)\n",
    "\n",
    "# Read all data\n",
    "data_hide_two = pd.concat([pd.read_csv(file, index_col=[0]) for file in files])\n",
    "\n",
    "result = data_hide_two.groupby(['model', 'split_method', 'metric', 'column'])['value'].agg([\"mean\", \"std\"])\n",
    "pivot_table = result.pivot_table(index=['model', 'split_method', 'column'], columns='metric', values=['mean', 'std'])\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_percentage) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_percentage) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_percentage) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding', 'Column'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Duas colunas são ocultadas. A indicada em 'Column' é o índice da coluna colocada como 'y'. A outra coluna ocultada segue a seguinte regra\")\n",
    "print(\"Obs: A 5º coluna é mostrada como '3' pq o índice começa como zero e pq eu tiro a 2º coluna para computar os dados\")\n",
    "print(\"  - if column = 1, then the other hidden column is 5: P(column_1 | columns \\ {column_1, column_5})\")\n",
    "print(\"  - if column = 5, then the other hidden column is 1: P(column_5 | columns \\ {column_1, column_5})\")\n",
    "new_pivot_table.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with one hidden column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'split_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2c67b8550e7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m pivot_table = data[\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'split_x_y_split_with_one_hot_encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m       & ((data.column == 1) | (data.column == 4))] \\\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'split_method'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metric'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'column'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"std\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/RBM/venv/lib/python3.6/site-packages/pandas-0.24.2-py3.6-linux-x86_64.egg/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'split_method'"
     ]
    }
   ],
   "source": [
    "pivot_table = data[\n",
    "        (data.split_method == 'split_x_y_split_with_one_hot_encoding') \n",
    "      & ((data.column == 1) | (data.column == 4))] \\\n",
    "    .groupby(['model', 'split_method', 'metric', 'column'])['value'] \\\n",
    "    .agg([\"mean\", \"std\"]) \\\n",
    "    .pivot_table(index=['model', 'split_method', 'column'], columns='metric', values=['mean', 'std'])\n",
    "\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_percentage) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_percentage) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_percentage) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding', 'Column'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Somente a coluna indicada está oculta\")\n",
    "print(\"A 5º coluna é 4 pq não deletei a 2º coluna\")\n",
    "print(\"  - P(column_n | columns \\ {column_n})\")\n",
    "\n",
    "new_pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao comparar as duas tabelas, se conclui que \n",
    "\n",
    "* remover a coluna 4 tira pouca informação na previsão da coluna 1;\n",
    "* remover a coluna 1 tira pouca informação na previsão da coluna 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'../evaluate_results/hide_two_hard_p1/outer/*.csv', recursive=True)\n",
    "files2 = glob.glob(f'../evaluate_results/hide_two_hard/outer/*.csv', recursive=True)\n",
    "\n",
    "# Read all data\n",
    "data_hide_two = pd.concat([pd.read_csv(file, index_col=[0]) for file in files])\n",
    "data_hide_two['column_y'] = 1\n",
    "data_hide_two['column_ignored'] = 0\n",
    "data_hide_two2 = pd.concat([pd.read_csv(file, index_col=[0]) for file in files2])\n",
    "data_hide_two2['column_y'] = 0\n",
    "data_hide_two2['column_ignored'] = 1\n",
    "\n",
    "data_hide_two = pd.concat((data_hide_two, data_hide_two2))\n",
    "\n",
    "result = data_hide_two.groupby(['model', 'split_method', 'metric', 'column_y', 'column_ignored'])['value'].agg([\"mean\", \"std\"])\n",
    "pivot_table = result.pivot_table(index=['model', 'split_method', 'column_y', 'column_ignored'], columns='metric', values=['mean', 'std'])\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_percentage) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_percentage) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_percentage) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding', 'Column y', 'Column ignored'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "new_pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = data[\n",
    "        (data.split_method == 'split_x_y_split_with_one_hot_encoding') \n",
    "      & ((data.column == 0) | (data.column == 1))] \\\n",
    "    .groupby(['model', 'split_method', 'metric', 'column'])['value'] \\\n",
    "    .agg([\"mean\", \"std\"]) \\\n",
    "    .pivot_table(index=['model', 'split_method', 'column'], columns='metric', values=['mean', 'std'])\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_percentage) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_percentage) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_percentage) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding', 'Column'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "new_pivot_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
