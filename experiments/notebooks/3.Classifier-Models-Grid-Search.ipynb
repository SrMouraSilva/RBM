{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"../evaluate_results/full/outer/LogisticRegression-split_x_y_split_with_one_hot_encoding-{'multi_class': ['auto'], 'solver': ['liblinear']}-cross_entropy-(1 of 5).csv\",\n",
       " \"../evaluate_results/full/outer/SVC-split_x_y_split_with_one_hot_encoding-{'C': [0.002, 2.0, 2000.0, 2000000.0, 2000000000.0, 2000000000000.0], 'gamma': [2e-13, 2e-10, 2e-07, 0.0002, 0.2, 200.0], 'kernel': ['rbf'], 'probability': [True]}-accuracy-(3 of 5).csv\",\n",
       " \"../evaluate_results/full/outer/LogisticRegression-split_x_y_with_bag_of_words-{'multi_class': ['auto'], 'solver': ['liblinear']}-cross_entropy-(2 of 5).csv\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = 'full'\n",
    "#dataset_path = 'small'\n",
    "\n",
    "files = glob.glob(f'../evaluate_results/{dataset_path}/outer/*.csv', recursive=True)\n",
    "\n",
    "print(len(files), 'files')\n",
    "files[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_params</th>\n",
       "      <th>column</th>\n",
       "      <th>i_outer</th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>refit</th>\n",
       "      <th>split_method</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'multi_class': 'auto', 'solver': 'liblinear'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'multi_class': ['auto'], 'solver': ['liblinea...</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>split_x_y_split_with_one_hot_encoding</td>\n",
       "      <td>0.475751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'multi_class': 'auto', 'solver': 'liblinear'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'multi_class': ['auto'], 'solver': ['liblinea...</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>split_x_y_split_with_one_hot_encoding</td>\n",
       "      <td>0.676674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      best_params  column  i_outer    metric  \\\n",
       "0  {'multi_class': 'auto', 'solver': 'liblinear'}       0        0  accuracy   \n",
       "1  {'multi_class': 'auto', 'solver': 'liblinear'}       0        0     hit@5   \n",
       "\n",
       "                model                                             params  \\\n",
       "0  LogisticRegression  {'multi_class': ['auto'], 'solver': ['liblinea...   \n",
       "1  LogisticRegression  {'multi_class': ['auto'], 'solver': ['liblinea...   \n",
       "\n",
       "           refit                           split_method     value  \n",
       "0  cross_entropy  split_x_y_split_with_one_hot_encoding  0.475751  \n",
       "1  cross_entropy  split_x_y_split_with_one_hot_encoding  0.676674  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all data\n",
    "data = pd.concat([pd.read_csv(file, index_col=[0]) for file in files])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>split_method</th>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">KNeighborsClassifier</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">split_x_y_split_with_one_hot_encoding</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.356083</td>\n",
       "      <td>0.131148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hit@5</th>\n",
       "      <td>0.525216</td>\n",
       "      <td>0.128174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map@5</th>\n",
       "      <td>0.303942</td>\n",
       "      <td>0.155788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         mean  \\\n",
       "model                split_method                          metric               \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding accuracy  0.356083   \n",
       "                                                           hit@5     0.525216   \n",
       "                                                           map@5     0.303942   \n",
       "\n",
       "                                                                          std  \n",
       "model                split_method                          metric              \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding accuracy  0.131148  \n",
       "                                                           hit@5     0.128174  \n",
       "                                                           map@5     0.155788  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = data.groupby(['model', 'split_method', 'metric'])['value'].agg([\"mean\", \"std\"])\n",
    "result.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result as pivot table\n",
    "\n",
    "(Beauty table bellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"5\" halign=\"left\">std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>map@5</th>\n",
       "      <th>mdcg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>map@5</th>\n",
       "      <th>mdcg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>split_method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">KNeighborsClassifier</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.356083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525216</td>\n",
       "      <td>0.303942</td>\n",
       "      <td>0.544766</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.128174</td>\n",
       "      <td>0.155788</td>\n",
       "      <td>0.103685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.342662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520976</td>\n",
       "      <td>0.300250</td>\n",
       "      <td>0.539627</td>\n",
       "      <td>0.135818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131489</td>\n",
       "      <td>0.156469</td>\n",
       "      <td>0.107570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LogisticRegression</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.389859</td>\n",
       "      <td>2.778379</td>\n",
       "      <td>0.593544</td>\n",
       "      <td>0.325379</td>\n",
       "      <td>0.591116</td>\n",
       "      <td>0.128102</td>\n",
       "      <td>0.643164</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.153554</td>\n",
       "      <td>0.096964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.342660</td>\n",
       "      <td>3.131092</td>\n",
       "      <td>0.515190</td>\n",
       "      <td>0.317795</td>\n",
       "      <td>0.544051</td>\n",
       "      <td>0.137130</td>\n",
       "      <td>0.695718</td>\n",
       "      <td>0.140499</td>\n",
       "      <td>0.160684</td>\n",
       "      <td>0.109393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLPClassifier</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.347435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552361</td>\n",
       "      <td>0.307099</td>\n",
       "      <td>0.556736</td>\n",
       "      <td>0.127203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>0.151721</td>\n",
       "      <td>0.096470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.352223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.560688</td>\n",
       "      <td>0.319760</td>\n",
       "      <td>0.563953</td>\n",
       "      <td>0.130594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117527</td>\n",
       "      <td>0.149939</td>\n",
       "      <td>0.099597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.397491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583678</td>\n",
       "      <td>0.335118</td>\n",
       "      <td>0.585620</td>\n",
       "      <td>0.122176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123908</td>\n",
       "      <td>0.157263</td>\n",
       "      <td>0.101471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.342274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553214</td>\n",
       "      <td>0.328394</td>\n",
       "      <td>0.568154</td>\n",
       "      <td>0.142473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137107</td>\n",
       "      <td>0.160132</td>\n",
       "      <td>0.108311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                mean  \\\n",
       "metric                                                      accuracy   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.356083   \n",
       "                     split_x_y_with_bag_of_words            0.342662   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.389859   \n",
       "                     split_x_y_with_bag_of_words            0.342660   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.347435   \n",
       "                     split_x_y_with_bag_of_words            0.352223   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.397491   \n",
       "                     split_x_y_with_bag_of_words            0.342274   \n",
       "\n",
       "                                                                          \\\n",
       "metric                                                     cross_entropy   \n",
       "model                split_method                                          \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding      2.778379   \n",
       "                     split_x_y_with_bag_of_words                3.131092   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                         hit@5   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.525216   \n",
       "                     split_x_y_with_bag_of_words            0.520976   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.593544   \n",
       "                     split_x_y_with_bag_of_words            0.515190   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.552361   \n",
       "                     split_x_y_with_bag_of_words            0.560688   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.583678   \n",
       "                     split_x_y_with_bag_of_words            0.553214   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                         map@5   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.303942   \n",
       "                     split_x_y_with_bag_of_words            0.300250   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.325379   \n",
       "                     split_x_y_with_bag_of_words            0.317795   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.307099   \n",
       "                     split_x_y_with_bag_of_words            0.319760   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.335118   \n",
       "                     split_x_y_with_bag_of_words            0.328394   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                          mdcg   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.544766   \n",
       "                     split_x_y_with_bag_of_words            0.539627   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.591116   \n",
       "                     split_x_y_with_bag_of_words            0.544051   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.556736   \n",
       "                     split_x_y_with_bag_of_words            0.563953   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.585620   \n",
       "                     split_x_y_with_bag_of_words            0.568154   \n",
       "\n",
       "                                                                 std  \\\n",
       "metric                                                      accuracy   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.131148   \n",
       "                     split_x_y_with_bag_of_words            0.135818   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.128102   \n",
       "                     split_x_y_with_bag_of_words            0.137130   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.127203   \n",
       "                     split_x_y_with_bag_of_words            0.130594   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.122176   \n",
       "                     split_x_y_with_bag_of_words            0.142473   \n",
       "\n",
       "                                                                          \\\n",
       "metric                                                     cross_entropy   \n",
       "model                split_method                                          \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding      0.643164   \n",
       "                     split_x_y_with_bag_of_words                0.695718   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                         hit@5   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.128174   \n",
       "                     split_x_y_with_bag_of_words            0.131489   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.113773   \n",
       "                     split_x_y_with_bag_of_words            0.140499   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.111177   \n",
       "                     split_x_y_with_bag_of_words            0.117527   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.123908   \n",
       "                     split_x_y_with_bag_of_words            0.137107   \n",
       "\n",
       "                                                                                \n",
       "metric                                                         map@5      mdcg  \n",
       "model                split_method                                               \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.155788  0.103685  \n",
       "                     split_x_y_with_bag_of_words            0.156469  0.107570  \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.153554  0.096964  \n",
       "                     split_x_y_with_bag_of_words            0.160684  0.109393  \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.151721  0.096470  \n",
       "                     split_x_y_with_bag_of_words            0.149939  0.099597  \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.157263  0.101471  \n",
       "                     split_x_y_with_bag_of_words            0.160132  0.108311  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table = result.pivot_table(index=['model', 'split_method'], columns='metric', values=['mean', 'std'])\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Cute' Pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MDCG</th>\n",
       "      <th>MAP@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">$k$-NN</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$35.61\\% \\pm 0.1311$</td>\n",
       "      <td>$52.52\\% \\pm 0.1282$</td>\n",
       "      <td>$0.5448 \\pm 0.1037$</td>\n",
       "      <td>$30.39\\% \\pm 0.1558$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$34.27\\% \\pm 0.1358$</td>\n",
       "      <td>$52.10\\% \\pm 0.1315$</td>\n",
       "      <td>$0.5396 \\pm 0.1076$</td>\n",
       "      <td>$30.03\\% \\pm 0.1565$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$38.99\\% \\pm 0.1281$</td>\n",
       "      <td>$59.35\\% \\pm 0.1138$</td>\n",
       "      <td>$0.5911 \\pm 0.09696$</td>\n",
       "      <td>$32.54\\% \\pm 0.1536$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$34.27\\% \\pm 0.1371$</td>\n",
       "      <td>$51.52\\% \\pm 0.1405$</td>\n",
       "      <td>$0.5441 \\pm 0.1094$</td>\n",
       "      <td>$31.78\\% \\pm 0.1607$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$34.74\\% \\pm 0.1272$</td>\n",
       "      <td>$55.24\\% \\pm 0.1112$</td>\n",
       "      <td>$0.5567 \\pm 0.09647$</td>\n",
       "      <td>$30.71\\% \\pm 0.1517$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$35.22\\% \\pm 0.1306$</td>\n",
       "      <td>$56.07\\% \\pm 0.1175$</td>\n",
       "      <td>$0.564 \\pm 0.0996$</td>\n",
       "      <td>$31.98\\% \\pm 0.1499$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$39.75\\% \\pm 0.1222$</td>\n",
       "      <td>$58.37\\% \\pm 0.1239$</td>\n",
       "      <td>$0.5856 \\pm 0.1015$</td>\n",
       "      <td>$33.51\\% \\pm 0.1573$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$34.23\\% \\pm 0.1425$</td>\n",
       "      <td>$55.32\\% \\pm 0.1371$</td>\n",
       "      <td>$0.5682 \\pm 0.1083$</td>\n",
       "      <td>$32.84\\% \\pm 0.1601$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Accuracy  \\\n",
       "Model               Embedding                                    \n",
       "$k$-NN              One-hot concatenated  $35.61\\% \\pm 0.1311$   \n",
       "                    Bag-of-words          $34.27\\% \\pm 0.1358$   \n",
       "Logistic Regression One-hot concatenated  $38.99\\% \\pm 0.1281$   \n",
       "                    Bag-of-words          $34.27\\% \\pm 0.1371$   \n",
       "MLP                 One-hot concatenated  $34.74\\% \\pm 0.1272$   \n",
       "                    Bag-of-words          $35.22\\% \\pm 0.1306$   \n",
       "SVC                 One-hot concatenated  $39.75\\% \\pm 0.1222$   \n",
       "                    Bag-of-words          $34.23\\% \\pm 0.1425$   \n",
       "\n",
       "                                                         Hit@5  \\\n",
       "Model               Embedding                                    \n",
       "$k$-NN              One-hot concatenated  $52.52\\% \\pm 0.1282$   \n",
       "                    Bag-of-words          $52.10\\% \\pm 0.1315$   \n",
       "Logistic Regression One-hot concatenated  $59.35\\% \\pm 0.1138$   \n",
       "                    Bag-of-words          $51.52\\% \\pm 0.1405$   \n",
       "MLP                 One-hot concatenated  $55.24\\% \\pm 0.1112$   \n",
       "                    Bag-of-words          $56.07\\% \\pm 0.1175$   \n",
       "SVC                 One-hot concatenated  $58.37\\% \\pm 0.1239$   \n",
       "                    Bag-of-words          $55.32\\% \\pm 0.1371$   \n",
       "\n",
       "                                                          MDCG  \\\n",
       "Model               Embedding                                    \n",
       "$k$-NN              One-hot concatenated   $0.5448 \\pm 0.1037$   \n",
       "                    Bag-of-words           $0.5396 \\pm 0.1076$   \n",
       "Logistic Regression One-hot concatenated  $0.5911 \\pm 0.09696$   \n",
       "                    Bag-of-words           $0.5441 \\pm 0.1094$   \n",
       "MLP                 One-hot concatenated  $0.5567 \\pm 0.09647$   \n",
       "                    Bag-of-words            $0.564 \\pm 0.0996$   \n",
       "SVC                 One-hot concatenated   $0.5856 \\pm 0.1015$   \n",
       "                    Bag-of-words           $0.5682 \\pm 0.1083$   \n",
       "\n",
       "                                                         MAP@5  \n",
       "Model               Embedding                                   \n",
       "$k$-NN              One-hot concatenated  $30.39\\% \\pm 0.1558$  \n",
       "                    Bag-of-words          $30.03\\% \\pm 0.1565$  \n",
       "Logistic Regression One-hot concatenated  $32.54\\% \\pm 0.1536$  \n",
       "                    Bag-of-words          $31.78\\% \\pm 0.1607$  \n",
       "MLP                 One-hot concatenated  $30.71\\% \\pm 0.1517$  \n",
       "                    Bag-of-words          $31.98\\% \\pm 0.1499$  \n",
       "SVC                 One-hot concatenated  $33.51\\% \\pm 0.1573$  \n",
       "                    Bag-of-words          $32.84\\% \\pm 0.1601$  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_percentage(x):\n",
    "    return '{:2.2%}'.format(x).replace('%', '\\%')\n",
    "\n",
    "def format_std(x):\n",
    "    return '{:.4}'.format(x)\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_std) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_std) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_std) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "new_pivot_table.to_latex(\"table.tex\", escape=False)\n",
    "new_pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset (hide two columns)\n",
    "\n",
    "### Two hidden columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duas colunas são ocultadas. A indicada em 'Column' é o índice da coluna colocada como 'y'. A outra coluna ocultada segue a seguinte regra\n",
      "Obs: A 5º coluna é mostrada como '3' pq o índice começa como zero e pq eu tiro a 2º coluna para computar os dados\n",
      "  - if column = 1, then the other hidden column is 5: P(column_1 | columns \\ {column_1, column_5})\n",
      "  - if column = 5, then the other hidden column is 1: P(column_5 | columns \\ {column_1, column_5})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MDCG</th>\n",
       "      <th>MAP@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">$k$-NN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No embedding</th>\n",
       "      <th>1</th>\n",
       "      <td>$20.18\\% \\pm 0.01349$</td>\n",
       "      <td>$39.75\\% \\pm 0.02071$</td>\n",
       "      <td>$0.4291 \\pm 0.01767$</td>\n",
       "      <td>$14.59\\% \\pm 0.00535$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$44.05\\% \\pm 0.0242$</td>\n",
       "      <td>$58.91\\% \\pm 0.0203$</td>\n",
       "      <td>$0.6037 \\pm 0.01766$</td>\n",
       "      <td>$42.51\\% \\pm 0.01449$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$24.06\\% \\pm 0.02254$</td>\n",
       "      <td>$47.39\\% \\pm 0.01177$</td>\n",
       "      <td>$0.4815 \\pm 0.01662$</td>\n",
       "      <td>$16.05\\% \\pm 0.005102$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$46.65\\% \\pm 0.0167$</td>\n",
       "      <td>$66.87\\% \\pm 0.009236$</td>\n",
       "      <td>$0.6516 \\pm 0.01039$</td>\n",
       "      <td>$44.30\\% \\pm 0.01327$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$25.13\\% \\pm 0.01952$</td>\n",
       "      <td>$46.83\\% \\pm 0.01893$</td>\n",
       "      <td>$0.4769 \\pm 0.01353$</td>\n",
       "      <td>$16.40\\% \\pm 0.007493$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Accuracy  \\\n",
       "Model               Embedding            Column                          \n",
       "$k$-NN              No embedding         1       $20.18\\% \\pm 0.01349$   \n",
       "                                         3        $44.05\\% \\pm 0.0242$   \n",
       "Logistic Regression One-hot concatenated 1       $24.06\\% \\pm 0.02254$   \n",
       "                                         3        $46.65\\% \\pm 0.0167$   \n",
       "SVC                 One-hot concatenated 1       $25.13\\% \\pm 0.01952$   \n",
       "\n",
       "                                                                  Hit@5  \\\n",
       "Model               Embedding            Column                           \n",
       "$k$-NN              No embedding         1        $39.75\\% \\pm 0.02071$   \n",
       "                                         3         $58.91\\% \\pm 0.0203$   \n",
       "Logistic Regression One-hot concatenated 1        $47.39\\% \\pm 0.01177$   \n",
       "                                         3       $66.87\\% \\pm 0.009236$   \n",
       "SVC                 One-hot concatenated 1        $46.83\\% \\pm 0.01893$   \n",
       "\n",
       "                                                                 MDCG  \\\n",
       "Model               Embedding            Column                         \n",
       "$k$-NN              No embedding         1       $0.4291 \\pm 0.01767$   \n",
       "                                         3       $0.6037 \\pm 0.01766$   \n",
       "Logistic Regression One-hot concatenated 1       $0.4815 \\pm 0.01662$   \n",
       "                                         3       $0.6516 \\pm 0.01039$   \n",
       "SVC                 One-hot concatenated 1       $0.4769 \\pm 0.01353$   \n",
       "\n",
       "                                                                  MAP@5  \n",
       "Model               Embedding            Column                          \n",
       "$k$-NN              No embedding         1        $14.59\\% \\pm 0.00535$  \n",
       "                                         3        $42.51\\% \\pm 0.01449$  \n",
       "Logistic Regression One-hot concatenated 1       $16.05\\% \\pm 0.005102$  \n",
       "                                         3        $44.30\\% \\pm 0.01327$  \n",
       "SVC                 One-hot concatenated 1       $16.40\\% \\pm 0.007493$  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(f'../evaluate_results/hide_two/outer/*.csv', recursive=True)\n",
    "\n",
    "# Read all data\n",
    "data_hide_two = pd.concat([pd.read_csv(file, index_col=[0]) for file in files])\n",
    "\n",
    "result = data_hide_two.groupby(['model', 'split_method', 'metric', 'column'])['value'].agg([\"mean\", \"std\"])\n",
    "pivot_table = result.pivot_table(index=['model', 'split_method', 'column'], columns='metric', values=['mean', 'std'])\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_std) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_std) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_std) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding', 'Column'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Duas colunas são ocultadas. A indicada em 'Column' é o índice da coluna colocada como 'y'. A outra coluna ocultada segue a seguinte regra\")\n",
    "print(\"Obs: A 5º coluna é mostrada como '3' pq o índice começa como zero e pq eu tiro a 2º coluna para computar os dados\")\n",
    "print(\"  - if column = 1, then the other hidden column is 5: P(column_1 | columns \\ {column_1, column_5})\")\n",
    "print(\"  - if column = 5, then the other hidden column is 1: P(column_5 | columns \\ {column_1, column_5})\")\n",
    "new_pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with one hidden column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somente a coluna indicada está oculta\n",
      "A 5º coluna é 4 pq não deletei a 2º coluna\n",
      "  - P(column_n | columns \\ {column_n})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MDCG</th>\n",
       "      <th>MAP@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">$k$-NN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$20.50\\% \\pm 0.01293$</td>\n",
       "      <td>$39.43\\% \\pm 0.03035$</td>\n",
       "      <td>$0.4272 \\pm 0.01974$</td>\n",
       "      <td>$14.50\\% \\pm 0.003722$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$44.01\\% \\pm 0.02206$</td>\n",
       "      <td>$60.16\\% \\pm 0.02256$</td>\n",
       "      <td>$0.6111 \\pm 0.01183$</td>\n",
       "      <td>$43.22\\% \\pm 0.01341$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$24.20\\% \\pm 0.01109$</td>\n",
       "      <td>$47.71\\% \\pm 0.01599$</td>\n",
       "      <td>$0.4834 \\pm 0.0125$</td>\n",
       "      <td>$16.06\\% \\pm 0.003287$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$47.57\\% \\pm 0.009918$</td>\n",
       "      <td>$66.96\\% \\pm 0.01218$</td>\n",
       "      <td>$0.6579 \\pm 0.006775$</td>\n",
       "      <td>$44.39\\% \\pm 0.01388$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$21.19\\% \\pm 0.02716$</td>\n",
       "      <td>$43.87\\% \\pm 0.02868$</td>\n",
       "      <td>$0.4537 \\pm 0.01814$</td>\n",
       "      <td>$15.62\\% \\pm 0.003772$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$42.20\\% \\pm 0.0204$</td>\n",
       "      <td>$62.29\\% \\pm 0.01188$</td>\n",
       "      <td>$0.616 \\pm 0.01249$</td>\n",
       "      <td>$42.48\\% \\pm 0.01522$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$25.40\\% \\pm 0.01053$</td>\n",
       "      <td>$45.03\\% \\pm 0.02116$</td>\n",
       "      <td>$0.4703 \\pm 0.01388$</td>\n",
       "      <td>$16.35\\% \\pm 0.006784$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$47.06\\% \\pm 0.01376$</td>\n",
       "      <td>$66.68\\% \\pm 0.01479$</td>\n",
       "      <td>$0.6518 \\pm 0.01176$</td>\n",
       "      <td>$44.60\\% \\pm 0.01115$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               Accuracy  \\\n",
       "Model               Embedding            Column                           \n",
       "$k$-NN              One-hot concatenated 1        $20.50\\% \\pm 0.01293$   \n",
       "                                         4        $44.01\\% \\pm 0.02206$   \n",
       "Logistic Regression One-hot concatenated 1        $24.20\\% \\pm 0.01109$   \n",
       "                                         4       $47.57\\% \\pm 0.009918$   \n",
       "MLP                 One-hot concatenated 1        $21.19\\% \\pm 0.02716$   \n",
       "                                         4         $42.20\\% \\pm 0.0204$   \n",
       "SVC                 One-hot concatenated 1        $25.40\\% \\pm 0.01053$   \n",
       "                                         4        $47.06\\% \\pm 0.01376$   \n",
       "\n",
       "                                                                 Hit@5  \\\n",
       "Model               Embedding            Column                          \n",
       "$k$-NN              One-hot concatenated 1       $39.43\\% \\pm 0.03035$   \n",
       "                                         4       $60.16\\% \\pm 0.02256$   \n",
       "Logistic Regression One-hot concatenated 1       $47.71\\% \\pm 0.01599$   \n",
       "                                         4       $66.96\\% \\pm 0.01218$   \n",
       "MLP                 One-hot concatenated 1       $43.87\\% \\pm 0.02868$   \n",
       "                                         4       $62.29\\% \\pm 0.01188$   \n",
       "SVC                 One-hot concatenated 1       $45.03\\% \\pm 0.02116$   \n",
       "                                         4       $66.68\\% \\pm 0.01479$   \n",
       "\n",
       "                                                                  MDCG  \\\n",
       "Model               Embedding            Column                          \n",
       "$k$-NN              One-hot concatenated 1        $0.4272 \\pm 0.01974$   \n",
       "                                         4        $0.6111 \\pm 0.01183$   \n",
       "Logistic Regression One-hot concatenated 1         $0.4834 \\pm 0.0125$   \n",
       "                                         4       $0.6579 \\pm 0.006775$   \n",
       "MLP                 One-hot concatenated 1        $0.4537 \\pm 0.01814$   \n",
       "                                         4         $0.616 \\pm 0.01249$   \n",
       "SVC                 One-hot concatenated 1        $0.4703 \\pm 0.01388$   \n",
       "                                         4        $0.6518 \\pm 0.01176$   \n",
       "\n",
       "                                                                  MAP@5  \n",
       "Model               Embedding            Column                          \n",
       "$k$-NN              One-hot concatenated 1       $14.50\\% \\pm 0.003722$  \n",
       "                                         4        $43.22\\% \\pm 0.01341$  \n",
       "Logistic Regression One-hot concatenated 1       $16.06\\% \\pm 0.003287$  \n",
       "                                         4        $44.39\\% \\pm 0.01388$  \n",
       "MLP                 One-hot concatenated 1       $15.62\\% \\pm 0.003772$  \n",
       "                                         4        $42.48\\% \\pm 0.01522$  \n",
       "SVC                 One-hot concatenated 1       $16.35\\% \\pm 0.006784$  \n",
       "                                         4        $44.60\\% \\pm 0.01115$  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table = data[\n",
    "        (data.split_method == 'split_x_y_split_with_one_hot_encoding') \n",
    "      & ((data.column == 1) | (data.column == 4))] \\\n",
    "    .groupby(['model', 'split_method', 'metric', 'column'])['value'] \\\n",
    "    .agg([\"mean\", \"std\"]) \\\n",
    "    .pivot_table(index=['model', 'split_method', 'column'], columns='metric', values=['mean', 'std'])\n",
    "\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_std) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_std) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_std) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding', 'Column'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Somente a coluna indicada está oculta\")\n",
    "print(\"A 5º coluna é 4 pq não deletei a 2º coluna\")\n",
    "print(\"  - P(column_n | columns \\ {column_n})\")\n",
    "\n",
    "new_pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao comparar as duas tabelas, se conclui que \n",
    "\n",
    "* remover a coluna 4 tira pouca informação na previsão da coluna 1;\n",
    "* remover a coluna 1 tira pouca informação na previsão da coluna 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
