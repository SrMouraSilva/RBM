{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"../evaluate_results/full/outer/LogisticRegression-split_x_y_split_with_one_hot_encoding-{'multi_class': ['auto'], 'solver': ['liblinear']}-cross_entropy-(1 of 5).csv\",\n",
       " \"../evaluate_results/full/outer/SVC-split_x_y_split_with_one_hot_encoding-{'C': [0.002, 2.0, 2000.0, 2000000.0, 2000000000.0, 2000000000000.0], 'gamma': [2e-13, 2e-10, 2e-07, 0.0002, 0.2, 200.0], 'kernel': ['rbf'], 'probability': [True]}-accuracy-(3 of 5).csv\",\n",
       " \"../evaluate_results/full/outer/LogisticRegression-split_x_y_with_bag_of_words-{'multi_class': ['auto'], 'solver': ['liblinear']}-cross_entropy-(2 of 5).csv\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def highlight_max(data):\n",
    "    percent = data.str.contains('%').any()\n",
    "\n",
    "    data = data.str.split(expand=True)\n",
    "    percent = data[0].str.contains('%').any()\n",
    "\n",
    "    data[0] = data[0].replace('\\\\\\%','', regex=True).replace('\\$','', regex=True).astype(float)\n",
    "    data[0] = np.where(data[0] == data[0].max(), '\\mathbf{'+ str(data[0].max()) + '}', data[0])\n",
    "    if percent:\n",
    "        return '$' + data[0] + '\\% ' + data[1] + ' ' + data[2]\n",
    "    else:\n",
    "        return '$' + data[0] + ' ' + data[1] + ' ' + data[2]\n",
    "\n",
    "    return data\n",
    "\n",
    "dataset_path = 'full'\n",
    "#dataset_path = 'small'\n",
    "\n",
    "files = glob.glob(f'../evaluate_results/{dataset_path}/outer/*.csv', recursive=True)\n",
    "\n",
    "print(len(files), 'files')\n",
    "files[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_params</th>\n",
       "      <th>column</th>\n",
       "      <th>i_outer</th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>refit</th>\n",
       "      <th>split_method</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'multi_class': 'auto', 'solver': 'liblinear'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'multi_class': ['auto'], 'solver': ['liblinea...</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>split_x_y_split_with_one_hot_encoding</td>\n",
       "      <td>0.475751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'multi_class': 'auto', 'solver': 'liblinear'}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hit@5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'multi_class': ['auto'], 'solver': ['liblinea...</td>\n",
       "      <td>cross_entropy</td>\n",
       "      <td>split_x_y_split_with_one_hot_encoding</td>\n",
       "      <td>0.676674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      best_params  column  i_outer    metric  \\\n",
       "0  {'multi_class': 'auto', 'solver': 'liblinear'}       0        0  accuracy   \n",
       "1  {'multi_class': 'auto', 'solver': 'liblinear'}       0        0     hit@5   \n",
       "\n",
       "                model                                             params  \\\n",
       "0  LogisticRegression  {'multi_class': ['auto'], 'solver': ['liblinea...   \n",
       "1  LogisticRegression  {'multi_class': ['auto'], 'solver': ['liblinea...   \n",
       "\n",
       "           refit                           split_method     value  \n",
       "0  cross_entropy  split_x_y_split_with_one_hot_encoding  0.475751  \n",
       "1  cross_entropy  split_x_y_split_with_one_hot_encoding  0.676674  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all data\n",
    "data = pd.concat([pd.read_csv(file, index_col=[0]) for file in files])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>split_method</th>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">KNeighborsClassifier</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">split_x_y_split_with_one_hot_encoding</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.356083</td>\n",
       "      <td>0.131148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hit@5</th>\n",
       "      <td>0.525216</td>\n",
       "      <td>0.128174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map@5</th>\n",
       "      <td>0.303942</td>\n",
       "      <td>0.155788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         mean  \\\n",
       "model                split_method                          metric               \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding accuracy  0.356083   \n",
       "                                                           hit@5     0.525216   \n",
       "                                                           map@5     0.303942   \n",
       "\n",
       "                                                                          std  \n",
       "model                split_method                          metric              \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding accuracy  0.131148  \n",
       "                                                           hit@5     0.128174  \n",
       "                                                           map@5     0.155788  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = data.groupby(['model', 'split_method', 'metric'])['value'].agg([\"mean\", \"std\"])\n",
    "result.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result as pivot table\n",
    "\n",
    "(Beauty table bellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"5\" halign=\"left\">std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>map@5</th>\n",
       "      <th>mdcg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>map@5</th>\n",
       "      <th>mdcg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>split_method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">KNeighborsClassifier</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.356083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525216</td>\n",
       "      <td>0.303942</td>\n",
       "      <td>0.544766</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.128174</td>\n",
       "      <td>0.155788</td>\n",
       "      <td>0.103685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.342662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520976</td>\n",
       "      <td>0.300250</td>\n",
       "      <td>0.539627</td>\n",
       "      <td>0.135818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131489</td>\n",
       "      <td>0.156469</td>\n",
       "      <td>0.107570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LogisticRegression</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.389859</td>\n",
       "      <td>2.778379</td>\n",
       "      <td>0.593544</td>\n",
       "      <td>0.325379</td>\n",
       "      <td>0.591116</td>\n",
       "      <td>0.128102</td>\n",
       "      <td>0.643164</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.153554</td>\n",
       "      <td>0.096964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.342660</td>\n",
       "      <td>3.131092</td>\n",
       "      <td>0.515190</td>\n",
       "      <td>0.317795</td>\n",
       "      <td>0.544051</td>\n",
       "      <td>0.137130</td>\n",
       "      <td>0.695718</td>\n",
       "      <td>0.140499</td>\n",
       "      <td>0.160684</td>\n",
       "      <td>0.109393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLPClassifier</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.347435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552361</td>\n",
       "      <td>0.307099</td>\n",
       "      <td>0.556736</td>\n",
       "      <td>0.127203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>0.151721</td>\n",
       "      <td>0.096470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.352223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.560688</td>\n",
       "      <td>0.319760</td>\n",
       "      <td>0.563953</td>\n",
       "      <td>0.130594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117527</td>\n",
       "      <td>0.149939</td>\n",
       "      <td>0.099597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th>split_x_y_split_with_one_hot_encoding</th>\n",
       "      <td>0.397491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583678</td>\n",
       "      <td>0.335118</td>\n",
       "      <td>0.585620</td>\n",
       "      <td>0.122176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123908</td>\n",
       "      <td>0.157263</td>\n",
       "      <td>0.101471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split_x_y_with_bag_of_words</th>\n",
       "      <td>0.342274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553214</td>\n",
       "      <td>0.328394</td>\n",
       "      <td>0.568154</td>\n",
       "      <td>0.142473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137107</td>\n",
       "      <td>0.160132</td>\n",
       "      <td>0.108311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                mean  \\\n",
       "metric                                                      accuracy   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.356083   \n",
       "                     split_x_y_with_bag_of_words            0.342662   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.389859   \n",
       "                     split_x_y_with_bag_of_words            0.342660   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.347435   \n",
       "                     split_x_y_with_bag_of_words            0.352223   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.397491   \n",
       "                     split_x_y_with_bag_of_words            0.342274   \n",
       "\n",
       "                                                                          \\\n",
       "metric                                                     cross_entropy   \n",
       "model                split_method                                          \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding      2.778379   \n",
       "                     split_x_y_with_bag_of_words                3.131092   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                         hit@5   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.525216   \n",
       "                     split_x_y_with_bag_of_words            0.520976   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.593544   \n",
       "                     split_x_y_with_bag_of_words            0.515190   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.552361   \n",
       "                     split_x_y_with_bag_of_words            0.560688   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.583678   \n",
       "                     split_x_y_with_bag_of_words            0.553214   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                         map@5   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.303942   \n",
       "                     split_x_y_with_bag_of_words            0.300250   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.325379   \n",
       "                     split_x_y_with_bag_of_words            0.317795   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.307099   \n",
       "                     split_x_y_with_bag_of_words            0.319760   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.335118   \n",
       "                     split_x_y_with_bag_of_words            0.328394   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                          mdcg   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.544766   \n",
       "                     split_x_y_with_bag_of_words            0.539627   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.591116   \n",
       "                     split_x_y_with_bag_of_words            0.544051   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.556736   \n",
       "                     split_x_y_with_bag_of_words            0.563953   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.585620   \n",
       "                     split_x_y_with_bag_of_words            0.568154   \n",
       "\n",
       "                                                                 std  \\\n",
       "metric                                                      accuracy   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.131148   \n",
       "                     split_x_y_with_bag_of_words            0.135818   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.128102   \n",
       "                     split_x_y_with_bag_of_words            0.137130   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.127203   \n",
       "                     split_x_y_with_bag_of_words            0.130594   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.122176   \n",
       "                     split_x_y_with_bag_of_words            0.142473   \n",
       "\n",
       "                                                                          \\\n",
       "metric                                                     cross_entropy   \n",
       "model                split_method                                          \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding      0.643164   \n",
       "                     split_x_y_with_bag_of_words                0.695718   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding           NaN   \n",
       "                     split_x_y_with_bag_of_words                     NaN   \n",
       "\n",
       "                                                                      \\\n",
       "metric                                                         hit@5   \n",
       "model                split_method                                      \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.128174   \n",
       "                     split_x_y_with_bag_of_words            0.131489   \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.113773   \n",
       "                     split_x_y_with_bag_of_words            0.140499   \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.111177   \n",
       "                     split_x_y_with_bag_of_words            0.117527   \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.123908   \n",
       "                     split_x_y_with_bag_of_words            0.137107   \n",
       "\n",
       "                                                                                \n",
       "metric                                                         map@5      mdcg  \n",
       "model                split_method                                               \n",
       "KNeighborsClassifier split_x_y_split_with_one_hot_encoding  0.155788  0.103685  \n",
       "                     split_x_y_with_bag_of_words            0.156469  0.107570  \n",
       "LogisticRegression   split_x_y_split_with_one_hot_encoding  0.153554  0.096964  \n",
       "                     split_x_y_with_bag_of_words            0.160684  0.109393  \n",
       "MLPClassifier        split_x_y_split_with_one_hot_encoding  0.151721  0.096470  \n",
       "                     split_x_y_with_bag_of_words            0.149939  0.099597  \n",
       "SVC                  split_x_y_split_with_one_hot_encoding  0.157263  0.101471  \n",
       "                     split_x_y_with_bag_of_words            0.160132  0.108311  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table = result.pivot_table(index=['model', 'split_method'], columns='metric', values=['mean', 'std'])\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Cute' Pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MDCG</th>\n",
       "      <th>MAP@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">$k$-NN</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$35.61\\% \\pm 13.11\\%$</td>\n",
       "      <td>$52.52\\% \\pm 12.82\\%$</td>\n",
       "      <td>$0.5448 \\pm 0.1037$</td>\n",
       "      <td>$30.39\\% \\pm 15.58\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$34.27\\% \\pm 13.58\\%$</td>\n",
       "      <td>$52.1\\% \\pm 13.15\\%$</td>\n",
       "      <td>$0.5396 \\pm 0.1076$</td>\n",
       "      <td>$30.03\\% \\pm 15.65\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$38.99\\% \\pm 12.81\\%$</td>\n",
       "      <td>$\\mathbf{59.35}\\% \\pm 11.38\\%$</td>\n",
       "      <td>$\\mathbf{0.5911} \\pm 0.0970$</td>\n",
       "      <td>$32.54\\% \\pm 15.36\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$34.27\\% \\pm 13.71\\%$</td>\n",
       "      <td>$51.52\\% \\pm 14.05\\%$</td>\n",
       "      <td>$0.5441 \\pm 0.1094$</td>\n",
       "      <td>$31.78\\% \\pm 16.07\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$34.74\\% \\pm 12.72\\%$</td>\n",
       "      <td>$55.24\\% \\pm 11.12\\%$</td>\n",
       "      <td>$0.5567 \\pm 0.0965$</td>\n",
       "      <td>$30.71\\% \\pm 15.17\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$35.22\\% \\pm 13.06\\%$</td>\n",
       "      <td>$56.07\\% \\pm 11.75\\%$</td>\n",
       "      <td>$0.564 \\pm 0.0996$</td>\n",
       "      <td>$31.98\\% \\pm 14.99\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th>One-hot concatenated</th>\n",
       "      <td>$\\mathbf{39.75}\\% \\pm 12.22\\%$</td>\n",
       "      <td>$58.37\\% \\pm 12.39\\%$</td>\n",
       "      <td>$0.5856 \\pm 0.1015$</td>\n",
       "      <td>$\\mathbf{33.51}\\% \\pm 15.73\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag-of-words</th>\n",
       "      <td>$34.23\\% \\pm 14.25\\%$</td>\n",
       "      <td>$55.32\\% \\pm 13.71\\%$</td>\n",
       "      <td>$0.5682 \\pm 0.1083$</td>\n",
       "      <td>$32.84\\% \\pm 16.01\\%$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Accuracy  \\\n",
       "Model               Embedding                                              \n",
       "$k$-NN              One-hot concatenated           $35.61\\% \\pm 13.11\\%$   \n",
       "                    Bag-of-words                   $34.27\\% \\pm 13.58\\%$   \n",
       "Logistic Regression One-hot concatenated           $38.99\\% \\pm 12.81\\%$   \n",
       "                    Bag-of-words                   $34.27\\% \\pm 13.71\\%$   \n",
       "MLP                 One-hot concatenated           $34.74\\% \\pm 12.72\\%$   \n",
       "                    Bag-of-words                   $35.22\\% \\pm 13.06\\%$   \n",
       "SVC                 One-hot concatenated  $\\mathbf{39.75}\\% \\pm 12.22\\%$   \n",
       "                    Bag-of-words                   $34.23\\% \\pm 14.25\\%$   \n",
       "\n",
       "                                                                   Hit@5  \\\n",
       "Model               Embedding                                              \n",
       "$k$-NN              One-hot concatenated           $52.52\\% \\pm 12.82\\%$   \n",
       "                    Bag-of-words                    $52.1\\% \\pm 13.15\\%$   \n",
       "Logistic Regression One-hot concatenated  $\\mathbf{59.35}\\% \\pm 11.38\\%$   \n",
       "                    Bag-of-words                   $51.52\\% \\pm 14.05\\%$   \n",
       "MLP                 One-hot concatenated           $55.24\\% \\pm 11.12\\%$   \n",
       "                    Bag-of-words                   $56.07\\% \\pm 11.75\\%$   \n",
       "SVC                 One-hot concatenated           $58.37\\% \\pm 12.39\\%$   \n",
       "                    Bag-of-words                   $55.32\\% \\pm 13.71\\%$   \n",
       "\n",
       "                                                                  MDCG  \\\n",
       "Model               Embedding                                            \n",
       "$k$-NN              One-hot concatenated           $0.5448 \\pm 0.1037$   \n",
       "                    Bag-of-words                   $0.5396 \\pm 0.1076$   \n",
       "Logistic Regression One-hot concatenated  $\\mathbf{0.5911} \\pm 0.0970$   \n",
       "                    Bag-of-words                   $0.5441 \\pm 0.1094$   \n",
       "MLP                 One-hot concatenated           $0.5567 \\pm 0.0965$   \n",
       "                    Bag-of-words                    $0.564 \\pm 0.0996$   \n",
       "SVC                 One-hot concatenated           $0.5856 \\pm 0.1015$   \n",
       "                    Bag-of-words                   $0.5682 \\pm 0.1083$   \n",
       "\n",
       "                                                                   MAP@5  \n",
       "Model               Embedding                                             \n",
       "$k$-NN              One-hot concatenated           $30.39\\% \\pm 15.58\\%$  \n",
       "                    Bag-of-words                   $30.03\\% \\pm 15.65\\%$  \n",
       "Logistic Regression One-hot concatenated           $32.54\\% \\pm 15.36\\%$  \n",
       "                    Bag-of-words                   $31.78\\% \\pm 16.07\\%$  \n",
       "MLP                 One-hot concatenated           $30.71\\% \\pm 15.17\\%$  \n",
       "                    Bag-of-words                   $31.98\\% \\pm 14.99\\%$  \n",
       "SVC                 One-hot concatenated  $\\mathbf{33.51}\\% \\pm 15.73\\%$  \n",
       "                    Bag-of-words                   $32.84\\% \\pm 16.01\\%$  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_percentage(x):\n",
    "    return '{:2.2%}'.format(x).replace('%', '\\%')\n",
    "\n",
    "def format_std(x):\n",
    "    return '{:.4f}'.format(x)\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_percentage) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_percentage) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_percentage) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "new_pivot_table.apply(highlight_max).to_latex(\"table.tex\", escape=False)\n",
    "new_pivot_table.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset (hide two columns)\n",
    "\n",
    "### Two hidden columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duas colunas são ocultadas. A indicada em 'Column' é o índice da coluna colocada como 'y'. A outra coluna ocultada segue a seguinte regra\n",
      "Obs: A 5º coluna é mostrada como '3' pq o índice começa como zero e pq eu tiro a 2º coluna para computar os dados\n",
      "  - if column = 1, then the other hidden column is 5: P(column_1 | columns \\ {column_1, column_5})\n",
      "  - if column = 5, then the other hidden column is 1: P(column_5 | columns \\ {column_1, column_5})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MDCG</th>\n",
       "      <th>MAP@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">$k$-NN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No embedding</th>\n",
       "      <th>1</th>\n",
       "      <td>$20.18\\% \\pm 1.35\\%$</td>\n",
       "      <td>$39.75\\% \\pm 2.07\\%$</td>\n",
       "      <td>$0.4291 \\pm 0.0177$</td>\n",
       "      <td>$14.59\\% \\pm 0.54\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$44.05\\% \\pm 2.42\\%$</td>\n",
       "      <td>$58.91\\% \\pm 2.03\\%$</td>\n",
       "      <td>$0.6037 \\pm 0.0177$</td>\n",
       "      <td>$42.51\\% \\pm 1.45\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$24.06\\% \\pm 2.25\\%$</td>\n",
       "      <td>$47.39\\% \\pm 1.18\\%$</td>\n",
       "      <td>$0.4815 \\pm 0.0166$</td>\n",
       "      <td>$16.05\\% \\pm 0.51\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$46.65\\% \\pm 1.67\\%$</td>\n",
       "      <td>$\\mathbf{66.87}\\% \\pm 0.92\\%$</td>\n",
       "      <td>$\\mathbf{0.6516} \\pm 0.0104$</td>\n",
       "      <td>$44.3\\% \\pm 1.33\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$20.92\\% \\pm 1.79\\%$</td>\n",
       "      <td>$43.5\\% \\pm 1.85\\%$</td>\n",
       "      <td>$0.4508 \\pm 0.0153$</td>\n",
       "      <td>$15.47\\% \\pm 0.13\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$42.71\\% \\pm 0.89\\%$</td>\n",
       "      <td>$62.29\\% \\pm 1.81\\%$</td>\n",
       "      <td>$0.6182 \\pm 0.0034$</td>\n",
       "      <td>$42.27\\% \\pm 1.33\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$25.13\\% \\pm 1.95\\%$</td>\n",
       "      <td>$46.83\\% \\pm 1.89\\%$</td>\n",
       "      <td>$0.4769 \\pm 0.0135$</td>\n",
       "      <td>$16.4\\% \\pm 0.75\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$\\mathbf{47.2}\\% \\pm 1.46\\%$</td>\n",
       "      <td>$66.45\\% \\pm 1.12\\%$</td>\n",
       "      <td>$0.6509 \\pm 0.0095$</td>\n",
       "      <td>$\\mathbf{44.48}\\% \\pm 1.22\\%$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     Accuracy  \\\n",
       "Model               Embedding            Column                                 \n",
       "$k$-NN              No embedding         1               $20.18\\% \\pm 1.35\\%$   \n",
       "                                         3               $44.05\\% \\pm 2.42\\%$   \n",
       "Logistic Regression One-hot concatenated 1               $24.06\\% \\pm 2.25\\%$   \n",
       "                                         3               $46.65\\% \\pm 1.67\\%$   \n",
       "MLP                 One-hot concatenated 1               $20.92\\% \\pm 1.79\\%$   \n",
       "                                         3               $42.71\\% \\pm 0.89\\%$   \n",
       "SVC                 One-hot concatenated 1               $25.13\\% \\pm 1.95\\%$   \n",
       "                                         3       $\\mathbf{47.2}\\% \\pm 1.46\\%$   \n",
       "\n",
       "                                                                         Hit@5  \\\n",
       "Model               Embedding            Column                                  \n",
       "$k$-NN              No embedding         1                $39.75\\% \\pm 2.07\\%$   \n",
       "                                         3                $58.91\\% \\pm 2.03\\%$   \n",
       "Logistic Regression One-hot concatenated 1                $47.39\\% \\pm 1.18\\%$   \n",
       "                                         3       $\\mathbf{66.87}\\% \\pm 0.92\\%$   \n",
       "MLP                 One-hot concatenated 1                 $43.5\\% \\pm 1.85\\%$   \n",
       "                                         3                $62.29\\% \\pm 1.81\\%$   \n",
       "SVC                 One-hot concatenated 1                $46.83\\% \\pm 1.89\\%$   \n",
       "                                         3                $66.45\\% \\pm 1.12\\%$   \n",
       "\n",
       "                                                                         MDCG  \\\n",
       "Model               Embedding            Column                                 \n",
       "$k$-NN              No embedding         1                $0.4291 \\pm 0.0177$   \n",
       "                                         3                $0.6037 \\pm 0.0177$   \n",
       "Logistic Regression One-hot concatenated 1                $0.4815 \\pm 0.0166$   \n",
       "                                         3       $\\mathbf{0.6516} \\pm 0.0104$   \n",
       "MLP                 One-hot concatenated 1                $0.4508 \\pm 0.0153$   \n",
       "                                         3                $0.6182 \\pm 0.0034$   \n",
       "SVC                 One-hot concatenated 1                $0.4769 \\pm 0.0135$   \n",
       "                                         3                $0.6509 \\pm 0.0095$   \n",
       "\n",
       "                                                                         MAP@5  \n",
       "Model               Embedding            Column                                 \n",
       "$k$-NN              No embedding         1                $14.59\\% \\pm 0.54\\%$  \n",
       "                                         3                $42.51\\% \\pm 1.45\\%$  \n",
       "Logistic Regression One-hot concatenated 1                $16.05\\% \\pm 0.51\\%$  \n",
       "                                         3                 $44.3\\% \\pm 1.33\\%$  \n",
       "MLP                 One-hot concatenated 1                $15.47\\% \\pm 0.13\\%$  \n",
       "                                         3                $42.27\\% \\pm 1.33\\%$  \n",
       "SVC                 One-hot concatenated 1                 $16.4\\% \\pm 0.75\\%$  \n",
       "                                         3       $\\mathbf{44.48}\\% \\pm 1.22\\%$  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(f'../evaluate_results/hide_two/outer/*.csv', recursive=True)\n",
    "\n",
    "# Read all data\n",
    "data_hide_two = pd.concat([pd.read_csv(file, index_col=[0]) for file in files])\n",
    "\n",
    "result = data_hide_two.groupby(['model', 'split_method', 'metric', 'column'])['value'].agg([\"mean\", \"std\"])\n",
    "pivot_table = result.pivot_table(index=['model', 'split_method', 'column'], columns='metric', values=['mean', 'std'])\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_percentage) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_percentage) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_percentage) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding', 'Column'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Duas colunas são ocultadas. A indicada em 'Column' é o índice da coluna colocada como 'y'. A outra coluna ocultada segue a seguinte regra\")\n",
    "print(\"Obs: A 5º coluna é mostrada como '3' pq o índice começa como zero e pq eu tiro a 2º coluna para computar os dados\")\n",
    "print(\"  - if column = 1, then the other hidden column is 5: P(column_1 | columns \\ {column_1, column_5})\")\n",
    "print(\"  - if column = 5, then the other hidden column is 1: P(column_5 | columns \\ {column_1, column_5})\")\n",
    "new_pivot_table.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with one hidden column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somente a coluna indicada está oculta\n",
      "A 5º coluna é 4 pq não deletei a 2º coluna\n",
      "  - P(column_n | columns \\ {column_n})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MDCG</th>\n",
       "      <th>MAP@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">$k$-NN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$20.50\\% \\pm 1.29\\%$</td>\n",
       "      <td>$39.43\\% \\pm 3.04\\%$</td>\n",
       "      <td>$0.4272 \\pm 0.0197$</td>\n",
       "      <td>$14.50\\% \\pm 0.37\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$44.01\\% \\pm 2.21\\%$</td>\n",
       "      <td>$60.16\\% \\pm 2.26\\%$</td>\n",
       "      <td>$0.6111 \\pm 0.0118$</td>\n",
       "      <td>$43.22\\% \\pm 1.34\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$24.20\\% \\pm 1.11\\%$</td>\n",
       "      <td>$47.71\\% \\pm 1.60\\%$</td>\n",
       "      <td>$0.4834 \\pm 0.0125$</td>\n",
       "      <td>$16.06\\% \\pm 0.33\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$47.57\\% \\pm 0.99\\%$</td>\n",
       "      <td>$66.96\\% \\pm 1.22\\%$</td>\n",
       "      <td>$0.6579 \\pm 0.0068$</td>\n",
       "      <td>$44.39\\% \\pm 1.39\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$21.19\\% \\pm 2.72\\%$</td>\n",
       "      <td>$43.87\\% \\pm 2.87\\%$</td>\n",
       "      <td>$0.4537 \\pm 0.0181$</td>\n",
       "      <td>$15.62\\% \\pm 0.38\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$42.20\\% \\pm 2.04\\%$</td>\n",
       "      <td>$62.29\\% \\pm 1.19\\%$</td>\n",
       "      <td>$0.6160 \\pm 0.0125$</td>\n",
       "      <td>$42.48\\% \\pm 1.52\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>1</th>\n",
       "      <td>$25.40\\% \\pm 1.05\\%$</td>\n",
       "      <td>$45.03\\% \\pm 2.12\\%$</td>\n",
       "      <td>$0.4703 \\pm 0.0139$</td>\n",
       "      <td>$16.35\\% \\pm 0.68\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$47.06\\% \\pm 1.38\\%$</td>\n",
       "      <td>$66.68\\% \\pm 1.48\\%$</td>\n",
       "      <td>$0.6518 \\pm 0.0118$</td>\n",
       "      <td>$44.60\\% \\pm 1.11\\%$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Accuracy  \\\n",
       "Model               Embedding            Column                         \n",
       "$k$-NN              One-hot concatenated 1       $20.50\\% \\pm 1.29\\%$   \n",
       "                                         4       $44.01\\% \\pm 2.21\\%$   \n",
       "Logistic Regression One-hot concatenated 1       $24.20\\% \\pm 1.11\\%$   \n",
       "                                         4       $47.57\\% \\pm 0.99\\%$   \n",
       "MLP                 One-hot concatenated 1       $21.19\\% \\pm 2.72\\%$   \n",
       "                                         4       $42.20\\% \\pm 2.04\\%$   \n",
       "SVC                 One-hot concatenated 1       $25.40\\% \\pm 1.05\\%$   \n",
       "                                         4       $47.06\\% \\pm 1.38\\%$   \n",
       "\n",
       "                                                                Hit@5  \\\n",
       "Model               Embedding            Column                         \n",
       "$k$-NN              One-hot concatenated 1       $39.43\\% \\pm 3.04\\%$   \n",
       "                                         4       $60.16\\% \\pm 2.26\\%$   \n",
       "Logistic Regression One-hot concatenated 1       $47.71\\% \\pm 1.60\\%$   \n",
       "                                         4       $66.96\\% \\pm 1.22\\%$   \n",
       "MLP                 One-hot concatenated 1       $43.87\\% \\pm 2.87\\%$   \n",
       "                                         4       $62.29\\% \\pm 1.19\\%$   \n",
       "SVC                 One-hot concatenated 1       $45.03\\% \\pm 2.12\\%$   \n",
       "                                         4       $66.68\\% \\pm 1.48\\%$   \n",
       "\n",
       "                                                                MDCG  \\\n",
       "Model               Embedding            Column                        \n",
       "$k$-NN              One-hot concatenated 1       $0.4272 \\pm 0.0197$   \n",
       "                                         4       $0.6111 \\pm 0.0118$   \n",
       "Logistic Regression One-hot concatenated 1       $0.4834 \\pm 0.0125$   \n",
       "                                         4       $0.6579 \\pm 0.0068$   \n",
       "MLP                 One-hot concatenated 1       $0.4537 \\pm 0.0181$   \n",
       "                                         4       $0.6160 \\pm 0.0125$   \n",
       "SVC                 One-hot concatenated 1       $0.4703 \\pm 0.0139$   \n",
       "                                         4       $0.6518 \\pm 0.0118$   \n",
       "\n",
       "                                                                MAP@5  \n",
       "Model               Embedding            Column                        \n",
       "$k$-NN              One-hot concatenated 1       $14.50\\% \\pm 0.37\\%$  \n",
       "                                         4       $43.22\\% \\pm 1.34\\%$  \n",
       "Logistic Regression One-hot concatenated 1       $16.06\\% \\pm 0.33\\%$  \n",
       "                                         4       $44.39\\% \\pm 1.39\\%$  \n",
       "MLP                 One-hot concatenated 1       $15.62\\% \\pm 0.38\\%$  \n",
       "                                         4       $42.48\\% \\pm 1.52\\%$  \n",
       "SVC                 One-hot concatenated 1       $16.35\\% \\pm 0.68\\%$  \n",
       "                                         4       $44.60\\% \\pm 1.11\\%$  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table = data[\n",
    "        (data.split_method == 'split_x_y_split_with_one_hot_encoding') \n",
    "      & ((data.column == 1) | (data.column == 4))] \\\n",
    "    .groupby(['model', 'split_method', 'metric', 'column'])['value'] \\\n",
    "    .agg([\"mean\", \"std\"]) \\\n",
    "    .pivot_table(index=['model', 'split_method', 'column'], columns='metric', values=['mean', 'std'])\n",
    "\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_percentage) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_percentage) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_percentage) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding', 'Column'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Somente a coluna indicada está oculta\")\n",
    "print(\"A 5º coluna é 4 pq não deletei a 2º coluna\")\n",
    "print(\"  - P(column_n | columns \\ {column_n})\")\n",
    "\n",
    "new_pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao comparar as duas tabelas, se conclui que \n",
    "\n",
    "* remover a coluna 4 tira pouca informação na previsão da coluna 1;\n",
    "* remover a coluna 1 tira pouca informação na previsão da coluna 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MDCG</th>\n",
       "      <th>MAP@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Column y</th>\n",
       "      <th>Column ignored</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">$k$-NN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>$38.41\\% \\pm 2.74\\%$</td>\n",
       "      <td>$56.31\\% \\pm 3.50\\%$</td>\n",
       "      <td>$0.5731 \\pm 0.0278$</td>\n",
       "      <td>$28.33\\% \\pm 1.06\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>$16.34\\% \\pm 1.45\\%$</td>\n",
       "      <td>$35.63\\% \\pm 2.66\\%$</td>\n",
       "      <td>$0.3931 \\pm 0.0161$</td>\n",
       "      <td>$14.27\\% \\pm 0.45\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>$40.49\\% \\pm 2.97\\%$</td>\n",
       "      <td>$61.91\\% \\pm 2.53\\%$</td>\n",
       "      <td>$0.6043 \\pm 0.0210$</td>\n",
       "      <td>$33.16\\% \\pm 0.62\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>$19.02\\% \\pm 1.16\\%$</td>\n",
       "      <td>$42.71\\% \\pm 1.87\\%$</td>\n",
       "      <td>$0.4420 \\pm 0.0118$</td>\n",
       "      <td>$16.41\\% \\pm 0.46\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>$34.75\\% \\pm 3.58\\%$</td>\n",
       "      <td>$56.55\\% \\pm 2.25\\%$</td>\n",
       "      <td>$0.5610 \\pm 0.0247$</td>\n",
       "      <td>$27.38\\% \\pm 0.53\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>$16.80\\% \\pm 0.95\\%$</td>\n",
       "      <td>$39.01\\% \\pm 4.15\\%$</td>\n",
       "      <td>$0.4180 \\pm 0.0160$</td>\n",
       "      <td>$15.07\\% \\pm 0.39\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>$41.55\\% \\pm 2.58\\%$</td>\n",
       "      <td>$60.29\\% \\pm 2.60\\%$</td>\n",
       "      <td>$0.6077 \\pm 0.0182$</td>\n",
       "      <td>$36.34\\% \\pm 1.53\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>$19.67\\% \\pm 1.10\\%$</td>\n",
       "      <td>$40.40\\% \\pm 2.05\\%$</td>\n",
       "      <td>$0.4326 \\pm 0.0142$</td>\n",
       "      <td>$16.66\\% \\pm 0.58\\%$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              Accuracy  \\\n",
       "Model               Embedding            Column y Column ignored                         \n",
       "$k$-NN              One-hot concatenated 0        1               $38.41\\% \\pm 2.74\\%$   \n",
       "                                         1        0               $16.34\\% \\pm 1.45\\%$   \n",
       "Logistic Regression One-hot concatenated 0        1               $40.49\\% \\pm 2.97\\%$   \n",
       "                                         1        0               $19.02\\% \\pm 1.16\\%$   \n",
       "MLP                 One-hot concatenated 0        1               $34.75\\% \\pm 3.58\\%$   \n",
       "                                         1        0               $16.80\\% \\pm 0.95\\%$   \n",
       "SVC                 One-hot concatenated 0        1               $41.55\\% \\pm 2.58\\%$   \n",
       "                                         1        0               $19.67\\% \\pm 1.10\\%$   \n",
       "\n",
       "                                                                                 Hit@5  \\\n",
       "Model               Embedding            Column y Column ignored                         \n",
       "$k$-NN              One-hot concatenated 0        1               $56.31\\% \\pm 3.50\\%$   \n",
       "                                         1        0               $35.63\\% \\pm 2.66\\%$   \n",
       "Logistic Regression One-hot concatenated 0        1               $61.91\\% \\pm 2.53\\%$   \n",
       "                                         1        0               $42.71\\% \\pm 1.87\\%$   \n",
       "MLP                 One-hot concatenated 0        1               $56.55\\% \\pm 2.25\\%$   \n",
       "                                         1        0               $39.01\\% \\pm 4.15\\%$   \n",
       "SVC                 One-hot concatenated 0        1               $60.29\\% \\pm 2.60\\%$   \n",
       "                                         1        0               $40.40\\% \\pm 2.05\\%$   \n",
       "\n",
       "                                                                                 MDCG  \\\n",
       "Model               Embedding            Column y Column ignored                        \n",
       "$k$-NN              One-hot concatenated 0        1               $0.5731 \\pm 0.0278$   \n",
       "                                         1        0               $0.3931 \\pm 0.0161$   \n",
       "Logistic Regression One-hot concatenated 0        1               $0.6043 \\pm 0.0210$   \n",
       "                                         1        0               $0.4420 \\pm 0.0118$   \n",
       "MLP                 One-hot concatenated 0        1               $0.5610 \\pm 0.0247$   \n",
       "                                         1        0               $0.4180 \\pm 0.0160$   \n",
       "SVC                 One-hot concatenated 0        1               $0.6077 \\pm 0.0182$   \n",
       "                                         1        0               $0.4326 \\pm 0.0142$   \n",
       "\n",
       "                                                                                 MAP@5  \n",
       "Model               Embedding            Column y Column ignored                        \n",
       "$k$-NN              One-hot concatenated 0        1               $28.33\\% \\pm 1.06\\%$  \n",
       "                                         1        0               $14.27\\% \\pm 0.45\\%$  \n",
       "Logistic Regression One-hot concatenated 0        1               $33.16\\% \\pm 0.62\\%$  \n",
       "                                         1        0               $16.41\\% \\pm 0.46\\%$  \n",
       "MLP                 One-hot concatenated 0        1               $27.38\\% \\pm 0.53\\%$  \n",
       "                                         1        0               $15.07\\% \\pm 0.39\\%$  \n",
       "SVC                 One-hot concatenated 0        1               $36.34\\% \\pm 1.53\\%$  \n",
       "                                         1        0               $16.66\\% \\pm 0.58\\%$  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(f'../evaluate_results/hide_two_hard_p1/outer/*.csv', recursive=True)\n",
    "files2 = glob.glob(f'../evaluate_results/hide_two_hard/outer/*.csv', recursive=True)\n",
    "\n",
    "# Read all data\n",
    "data_hide_two = pd.concat([pd.read_csv(file, index_col=[0]) for file in files])\n",
    "data_hide_two['column_y'] = 1\n",
    "data_hide_two['column_ignored'] = 0\n",
    "data_hide_two2 = pd.concat([pd.read_csv(file, index_col=[0]) for file in files2])\n",
    "data_hide_two2['column_y'] = 0\n",
    "data_hide_two2['column_ignored'] = 1\n",
    "\n",
    "data_hide_two = pd.concat((data_hide_two, data_hide_two2))\n",
    "\n",
    "result = data_hide_two.groupby(['model', 'split_method', 'metric', 'column_y', 'column_ignored'])['value'].agg([\"mean\", \"std\"])\n",
    "pivot_table = result.pivot_table(index=['model', 'split_method', 'column_y', 'column_ignored'], columns='metric', values=['mean', 'std'])\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_percentage) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_percentage) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_percentage) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding', 'Column y', 'Column ignored'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "new_pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>MDCG</th>\n",
       "      <th>MAP@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">$k$-NN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>0</th>\n",
       "      <td>$42.20\\% \\pm 2.85\\%$</td>\n",
       "      <td>$57.80\\% \\pm 2.29\\%$</td>\n",
       "      <td>$0.5933 \\pm 0.0181$</td>\n",
       "      <td>$25.88\\% \\pm 0.94\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$20.50\\% \\pm 1.29\\%$</td>\n",
       "      <td>$39.43\\% \\pm 3.04\\%$</td>\n",
       "      <td>$0.4272 \\pm 0.0197$</td>\n",
       "      <td>$14.50\\% \\pm 0.37\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>0</th>\n",
       "      <td>$45.67\\% \\pm 2.41\\%$</td>\n",
       "      <td>$64.14\\% \\pm 2.79\\%$</td>\n",
       "      <td>$0.6343 \\pm 0.0198$</td>\n",
       "      <td>$31.65\\% \\pm 0.69\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$24.20\\% \\pm 1.11\\%$</td>\n",
       "      <td>$47.71\\% \\pm 1.60\\%$</td>\n",
       "      <td>$0.4834 \\pm 0.0125$</td>\n",
       "      <td>$16.06\\% \\pm 0.33\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MLP</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>0</th>\n",
       "      <td>$42.06\\% \\pm 3.81\\%$</td>\n",
       "      <td>$59.51\\% \\pm 3.44\\%$</td>\n",
       "      <td>$0.6044 \\pm 0.0288$</td>\n",
       "      <td>$26.72\\% \\pm 0.89\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$21.19\\% \\pm 2.72\\%$</td>\n",
       "      <td>$43.87\\% \\pm 2.87\\%$</td>\n",
       "      <td>$0.4537 \\pm 0.0181$</td>\n",
       "      <td>$15.62\\% \\pm 0.38\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVC</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">One-hot concatenated</th>\n",
       "      <th>0</th>\n",
       "      <td>$46.27\\% \\pm 1.96\\%$</td>\n",
       "      <td>$63.30\\% \\pm 2.67\\%$</td>\n",
       "      <td>$0.6333 \\pm 0.0157$</td>\n",
       "      <td>$35.80\\% \\pm 1.38\\%$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$25.40\\% \\pm 1.05\\%$</td>\n",
       "      <td>$45.03\\% \\pm 2.12\\%$</td>\n",
       "      <td>$0.4703 \\pm 0.0139$</td>\n",
       "      <td>$16.35\\% \\pm 0.68\\%$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Accuracy  \\\n",
       "Model               Embedding            Column                         \n",
       "$k$-NN              One-hot concatenated 0       $42.20\\% \\pm 2.85\\%$   \n",
       "                                         1       $20.50\\% \\pm 1.29\\%$   \n",
       "Logistic Regression One-hot concatenated 0       $45.67\\% \\pm 2.41\\%$   \n",
       "                                         1       $24.20\\% \\pm 1.11\\%$   \n",
       "MLP                 One-hot concatenated 0       $42.06\\% \\pm 3.81\\%$   \n",
       "                                         1       $21.19\\% \\pm 2.72\\%$   \n",
       "SVC                 One-hot concatenated 0       $46.27\\% \\pm 1.96\\%$   \n",
       "                                         1       $25.40\\% \\pm 1.05\\%$   \n",
       "\n",
       "                                                                Hit@5  \\\n",
       "Model               Embedding            Column                         \n",
       "$k$-NN              One-hot concatenated 0       $57.80\\% \\pm 2.29\\%$   \n",
       "                                         1       $39.43\\% \\pm 3.04\\%$   \n",
       "Logistic Regression One-hot concatenated 0       $64.14\\% \\pm 2.79\\%$   \n",
       "                                         1       $47.71\\% \\pm 1.60\\%$   \n",
       "MLP                 One-hot concatenated 0       $59.51\\% \\pm 3.44\\%$   \n",
       "                                         1       $43.87\\% \\pm 2.87\\%$   \n",
       "SVC                 One-hot concatenated 0       $63.30\\% \\pm 2.67\\%$   \n",
       "                                         1       $45.03\\% \\pm 2.12\\%$   \n",
       "\n",
       "                                                                MDCG  \\\n",
       "Model               Embedding            Column                        \n",
       "$k$-NN              One-hot concatenated 0       $0.5933 \\pm 0.0181$   \n",
       "                                         1       $0.4272 \\pm 0.0197$   \n",
       "Logistic Regression One-hot concatenated 0       $0.6343 \\pm 0.0198$   \n",
       "                                         1       $0.4834 \\pm 0.0125$   \n",
       "MLP                 One-hot concatenated 0       $0.6044 \\pm 0.0288$   \n",
       "                                         1       $0.4537 \\pm 0.0181$   \n",
       "SVC                 One-hot concatenated 0       $0.6333 \\pm 0.0157$   \n",
       "                                         1       $0.4703 \\pm 0.0139$   \n",
       "\n",
       "                                                                MAP@5  \n",
       "Model               Embedding            Column                        \n",
       "$k$-NN              One-hot concatenated 0       $25.88\\% \\pm 0.94\\%$  \n",
       "                                         1       $14.50\\% \\pm 0.37\\%$  \n",
       "Logistic Regression One-hot concatenated 0       $31.65\\% \\pm 0.69\\%$  \n",
       "                                         1       $16.06\\% \\pm 0.33\\%$  \n",
       "MLP                 One-hot concatenated 0       $26.72\\% \\pm 0.89\\%$  \n",
       "                                         1       $15.62\\% \\pm 0.38\\%$  \n",
       "SVC                 One-hot concatenated 0       $35.80\\% \\pm 1.38\\%$  \n",
       "                                         1       $16.35\\% \\pm 0.68\\%$  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table = data[\n",
    "        (data.split_method == 'split_x_y_split_with_one_hot_encoding') \n",
    "      & ((data.column == 0) | (data.column == 1))] \\\n",
    "    .groupby(['model', 'split_method', 'metric', 'column'])['value'] \\\n",
    "    .agg([\"mean\", \"std\"]) \\\n",
    "    .pivot_table(index=['model', 'split_method', 'column'], columns='metric', values=['mean', 'std'])\n",
    "\n",
    "\n",
    "new_pivot_table = pd.DataFrame({\n",
    "    'Accuracy': '$' + pivot_table['mean']['accuracy'].map(format_percentage) + ' \\pm ' + pivot_table['std']['accuracy'].map(format_percentage) + \"$\",\n",
    "    'Hit@5':    '$' + pivot_table['mean']['hit@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['hit@5'].map(format_percentage) + \"$\",\n",
    "    'MDCG':     '$' + pivot_table['mean']['mdcg'].map(format_std) + ' \\pm ' + pivot_table['std']['mdcg'].map(format_std) + \"$\",\n",
    "    'MAP@5':    '$' + pivot_table['mean']['map@5'].map(format_percentage) + ' \\pm ' + pivot_table['std']['map@5'].map(format_percentage) + \"$\",\n",
    "})\n",
    "\n",
    "new_pivot_table.index.set_names(['Model','Embedding', 'Column'],inplace=True)\n",
    "new_pivot_table.rename(index={\n",
    "    'split_x_y': 'No embedding',\n",
    "    'split_x_y_split_with_one_hot_encoding': 'One-hot concatenated',\n",
    "    'split_x_y_with_bag_of_words': 'Bag-of-words',\n",
    "    'KNeighborsClassifier': '$k$-NN',\n",
    "    'LogisticRegression': 'Logistic Regression',\n",
    "    'MLPClassifier': 'MLP',\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "new_pivot_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
